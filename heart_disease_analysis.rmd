---
subtitle: "MA8701 Advanced Statistical Learning V2023"
title: "Compulsory exercise: Team Supergreat"
author: "Nora Aasen, Elias Angelsen, Jonas Nordstr?m"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  # html_document
  pdf_document
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = FALSE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",
                      fig.width=6, fig.height=4.5,fig.align = "center")
```


```{r Loading Packages,eval=TRUE,echo=FALSE}
# Load libraries
library(naniar)
library(mice)
library(glmnet)
library(tidyr)
library(dplyr)
library(caret)
library(ggcorrplot)
library(ggplot2)
library(e1071) #If we use KNN for imputation of education (multiclass)
```

# Introduction

In this project we have studied the [Framingham Coronary Heart Disease Dataset](https://www.kaggle.com/datasets/dileep070/heart-disease-prediction-using-logistic-regression?fbclid=IwAR1LE3P3vM1SyHBifotrNdXoKGv7szGR07labEAQo6XUqV9Pi90vtAp4mS4). This dataset contains patient information for inhabitants in Framingham, Massachusetts, and is typically used to predict the chance of getting coronary heart disease (CHD) within the next 10 years. For this project, however, we intend to use lasso to find the most important risk factors.


We start by examining the dataset. 


## Exploratory Analysis
```{r Loading Data}
# Load and look at data
# data <- framingham # Just if manual import
data <- read.csv("framingham.csv")
data_dim = dim(data)
pos_response = sum(data$TenYearCHD==1)
str(data)


ggplot(gather(data), aes(value)) + 
    geom_histogram(bins = 16) + 
    facet_wrap(~key, scales = 'free_x')

# Code education as a factor variable instead
data$education = factor(data$education, labels = c("none","hs","college","post-grad"))

```

This data set contains `r data_dim[1]` observations, `r data_dim[2]-1` covariates and a binary response variable `TenYearCHD`, thus we will try to fit a logistic regression model. The response variable has `r pos_response` observations that are 1, which equals about `r round(pos_response/data_dim[1]*100,1)`\% of the total observations. Most of our covariates are either binary, or numeric. However, we notice that the variable education is most likely a categorical covariate. We could not find any further elaboration for which four categories the numbers represent, so based on the frequency of each value and naive guessing we changed it to a factor variable and defined the four categories as `r names(summary(data$education))[1:4]`.

The next thing we looked at was the number of missing data in our data set.

```{r plot missing data}
# Look at the missing data
md_mat = md.pattern(data, rotate.names = T, plot = T) # Can we make these plots prettier?
gg_miss_var(data)

```


As we can see there are six covariates that has missing data: `glucose`, `education`, `BPMeds`, `totChol`, `cigsPerDay`, and `BMI`. We cannot use the rows that contain missing values as is. The easiest solution is to remove all rows that contains `NA`'s. This is the \textit{complete case} solution.  

```{r complete case}
# Make a dataset containing only the complete cases
df_complete <- data[complete.cases(data), ]
data_dim_c = dim(df_complete)
pos_response_c = sum(df_complete$TenYearCHD==1)
```

The complete data set contains `r data_dim_c[1]` observations and the response variable has `r pos_response` observations that are 1, which equals about `r round(pos_response_c/data_dim_c[1]*100,1)`\% of the total observations. As we can see, the proportion of positive observations in the response is the same, which is a good indicator that our data is missing at random (MAR), and it is therefore possible to do imputation.

From the exploratory analysis we see that there are many missing data points. However, the complete case data set is also quite large. Our main focus for this project will therefore be to compare the results from doing lasso on the complete case with the results from doing lasso on an imputed data set. 


```{r exp analysis, eval = F}
# Is it of interest to consider a correlation plot in this case? 

# Make a correlation plot 
cor_mat = cor(subset(df_complete, select = -education)) # Cannot compute correlation with factor variables
ggcorrplot(cor_mat, hc.order = TRUE, type = "lower",
   outline.col = "white",
   colors = c("blue", "white", "red"))
```


# Missing Data

In our data set, we have some missing values, and we are going to handle these missing values in a slightly more refined manner than just considering the complete case (although our approach will be focused on being exploratory/explicit for the sake of learning instead of "optimal").

First, as a theoretical warm-up, recall that there are several types of mechanisms for missing data.
Let $Z = (X,y)$ denote the full collection of covariates and responses, respectively, and we let a subscript mis/obs indicate restricting $Z$ or $X$ to the missing or observed parts, respectively.
We may form an indicator (0-1) matrix $R$ indicating missing (0) covariates and observed (1) covariates. 
Assume $\psi$ is short notation for the parameters in the distribution of $R$.

The missing data may be characterized by the conditioning in the distribution of $R$.
We define the data to be:
\begin{itemize}
  \item missing completely at random (MCAR) if $P(R | Z, \psi) = P(R | \psi)$,
  \item missing at random (MAR) if $P(R | Z, \psi) = P(R | Z_{obs}, \psi)$,
  \item missing not at random (MNAR) if $P(R | Z, \psi) = P(R | Z, \psi)$ (we don't have MCAR or MAR).
\end{itemize}

By exploring for example the missing pattern of the variable cigsPerDay, we obtain a clear indication that our missing mechanism is not MCAR.
No non-smoker has failed to answer the question "how may cigarettes do you smoke a day?", which is a question only aimed at smokers. 
The simple explanation may be that the survey they answered automatically fills in $0$ for cigsPerDay if you claim to be a non-smoker. 
In more mathematical terms, cigsPerDay depends on the observed answer to "do you smoke?" (found in variable currentSmoker), indicating that we do not work with MCAR data.
Luckily, most methods are applicable if our missingness is at least MAR. 

We will assume that the missing mechanism is MAR, as there is no clear reason to suspect it to be MNAR. 
A pressing obstruction to being MAR can again be found in cigsPerDay. In the real world, if smokers have failed to report cigsPerDay, it may for example be because they smoke so much that they are ashamed to answer the question (and skips it), but we will simply assume that such a thing is not happening, as we trust people to answer truthfully (often, at least) if they volunteer for medical studies. 

To treat the missing data, we will use single imputation, as multiple imputation may cause difficulties with the resulting inference, as Rubins rules need to be combined with the Lasso, bootstrap and concluding inference. 

The single imputation technique we will use is simply regression imputation, where we adapt our regression technique depending on the type of variable imputed. For continuous variables, we simply use a linear regression model. For binary variables, we use logistic regression to classify their values, and for the variable "education", which is a four-class variable, we have utilized kNN for multiclass imputation. 

To avoid encountering observations with more than one missing value, and hence problems with regressing, we remove all samples with more than one NA. 

Our data is split into training and test sets, of sizes approximately $80%$ and $20%$ of the original dataset, respectively.
In order to avoid data leakage in our imputation if the test set, we fit the imputation models on the training set.
Note that we do not include the response (TenYearCHD) in the regression, and in order to avoid too much correlation between the imputed samples, we always base the regression models on the complete case data, instead of letting the imputed values for variable $n$ regress to impute variable $n+1$.  

First, we are removing all samples with more than one covariate missing, as this is only $61$ samples. 

```{r Clean Missing Data}

# Setting seed expressing our love for MA8701
set.seed(8701)

# Throwing out the samples with two or more NAs from the data
miss <- c()
for(i in 1:nrow(data)) {
  if(sum(is.na(data[i,])) > 1){
    miss <- append(miss,i)
    }  
}

data_m <- data[-miss,]

# length(miss) # This number should be 61 if done correctly (61 came from manually counting in the md.pattern-plot below)

# Exploring data_m

md.pattern(data_m)
gg_miss_var(data_m)


```


We further split the data into a training and test set, following the training-test-ratio that we have previously set.

``` {r Missing data split}

# Assigning which values should go where by randomly sampling the indices. 
tr = 7/10 # train ratio
dim_data_m = dim(data_m)[1]
size_split_m = round(dim_data_m*tr)
spl_dat_m = sample(1:dim_data_m, size = size_split_m)

# Making training and test data
train_data_m = data_m[spl_dat_m,]
test_data_m = data_m[-spl_dat_m,]

# Making training and test data for covariates and response separately.

X_dat_m = data_m[,-dim(data_m)[2]] # Remove the column with response?
x.train_dat_m = X_dat_m[spl_dat_m,]
x.test_dat_m = X_dat_m[-spl_dat_m,]
y.train_dat_m = data_m$TenYearCHD[spl_dat_m]
y.test_dat_m = data_m$TenYearCHD[-spl_dat_m]


```

Using the above data sets, we make regression models for each missing variable based on the data we have. 
These automatically neglects NA's. 

``` {r Missing data regression models}

# We fit linear models on the training set for glucose, cigsPerDay, BMI, totChol, heartRate.
fit_for_simp_glucose_m <- lm(glucose ~., data = x.train_dat_m)    # Linear model for glucose
fit_for_simp_cigs_m <- lm(cigsPerDay ~., data = x.train_dat_m)    # Linear model for cigsPerDay
fit_for_simp_BMI_m <- lm(BMI ~., data = x.train_dat_m)            # Linear model for BMI
fit_for_simp_totChol_m <- lm(totChol ~., data = x.train_dat_m)    # Linear model for totChol
fit_for_simp_heartRate_m <- lm(heartRate ~., data = x.train_dat_m)# Linear model for heartRate 

# We fit a logistic model on the training set for BPMeds, being a binary variable.
fit_for_simp_BPMeds_m <- glm(BPMeds ~., data = x.train_dat_m, family = "binomial") #Logistic model for BPMeds

# We fit a KNN model on the training set for education, being a multi-class variable.
fit_for_simp_edu_m <- gknn(education ~., data = x.train_dat_m) # kNN model for education

```

To predict, we pick out those samples with missing values of each variable from the training and test set.
Note that we are imputing for both the training and test set, even though the sampled (therefore "random") split into training and test set may have sorted all NA's of a variable (e.g. heartRate) into a single set (i.e. into either training or test set).
This is not a problem, as we are only picking out the incomplete cases. Therefore, predicting and filling in the missing values is a vacuous operation, not yielding any problems.

``` {r Missing data which-to-predict}

# Pick out those variables with missing glucose from the training and test set.
train_data_to_pred_gluc_m = ic(x.train_dat_m)
train_data_to_pred_gluc_m = train_data_to_pred_gluc_m[ici(train_data_to_pred_gluc_m$glucose),] 
test_data_to_pred_gluc_m = ic(x.test_dat_m)
test_data_to_pred_gluc_m = test_data_to_pred_gluc_m[ici(test_data_to_pred_gluc_m$glucose),]

# Pick out those variables with missing cigsPerDay from the training and test set.
train_data_to_pred_cigs_m = ic(x.train_dat_m)
train_data_to_pred_cigs_m = train_data_to_pred_cigs_m[ici(train_data_to_pred_cigs_m$cigsPerDay),]
test_data_to_pred_cigs_m = ic(x.test_dat_m)
test_data_to_pred_cigs_m = test_data_to_pred_cigs_m[ici(test_data_to_pred_cigs_m$cigsPerDay),]

# Pick out those variables with missing BMI from the training and test set.
train_data_to_pred_BMI_m = ic(x.train_dat_m)
train_data_to_pred_BMI_m = train_data_to_pred_BMI_m[ici(train_data_to_pred_BMI_m$BMI),]
test_data_to_pred_BMI_m = ic(x.test_dat_m)
test_data_to_pred_BMI_m = test_data_to_pred_BMI_m[ici(test_data_to_pred_BMI_m$BMI),]

# Pick out those variables with missing totChol from the training and test set.
train_data_to_pred_totChol_m = ic(x.train_dat_m)
train_data_to_pred_totChol_m = train_data_to_pred_totChol_m[ici(train_data_to_pred_totChol_m$totChol),]
test_data_to_pred_totChol_m = ic(x.test_dat_m)
test_data_to_pred_totChol_m = test_data_to_pred_totChol_m[ici(test_data_to_pred_totChol_m$totChol),]

# Pick out those variables with missing heartRate from the training and test set.
train_data_to_pred_heartRate_m = ic(x.train_dat_m)
train_data_to_pred_heartRate_m = train_data_to_pred_heartRate_m[ici(train_data_to_pred_heartRate_m$heartRate),]
test_data_to_pred_heartRate_m = ic(x.test_dat_m)
test_data_to_pred_heartRate_m = test_data_to_pred_heartRate_m[ici(test_data_to_pred_heartRate_m$heartRate),]

# Pick out those variables with missing BPMeds from the training and test set.
train_data_to_pred_BPMeds_m = ic(x.train_dat_m)
train_data_to_pred_BPMeds_m = train_data_to_pred_BPMeds_m[ici(train_data_to_pred_BPMeds_m$BPMeds),]
test_data_to_pred_BPMeds_m = ic(x.test_dat_m)
test_data_to_pred_BPMeds_m = test_data_to_pred_BPMeds_m[ici(test_data_to_pred_BPMeds_m$BPMeds),]

# Pick out those variables with missing education from the training and test set.
train_data_to_pred_edu_m = ic(x.train_dat_m)
train_data_to_pred_edu_m = train_data_to_pred_edu_m[ici(train_data_to_pred_edu_m$education),]
test_data_to_pred_edu_m = ic(x.test_dat_m)
test_data_to_pred_edu_m = test_data_to_pred_edu_m[ici(test_data_to_pred_edu_m$education),]

```

We predict new samples for the imputation.

``` {r Missing Data predictions}

# Predicting the values to impute for glucose on the training and test data.
pred_glucose_train_m <- predict(fit_for_simp_glucose_m, newdata = train_data_to_pred_gluc_m) 
pred_glucose_test_m <- predict(fit_for_simp_glucose_m, newdata = test_data_to_pred_gluc_m)

# Predicting the values to impute for cigsPerDay on the training and test data.
pred_cigs_train_m <- predict(fit_for_simp_cigs_m, newdata = train_data_to_pred_cigs_m) 
pred_cigs_test_m <- predict(fit_for_simp_cigs_m, newdata = test_data_to_pred_cigs_m)

# Predicting the values to impute for BMI on the training and test data.
pred_BMI_train_m <- predict(fit_for_simp_BMI_m, newdata = train_data_to_pred_BMI_m) 
pred_BMI_test_m <- predict(fit_for_simp_BMI_m, newdata = test_data_to_pred_BMI_m)

# Predicting the values to impute for totChol on the training and test data.
pred_totChol_train_m <- predict(fit_for_simp_totChol_m, newdata = train_data_to_pred_totChol_m) 
pred_totChol_test_m <- predict(fit_for_simp_totChol_m, newdata = test_data_to_pred_totChol_m)

# Predicting the values to impute for heartRate on the training and test data.
pred_heartRate_train_m <- predict(fit_for_simp_heartRate_m, newdata = train_data_to_pred_heartRate_m) 
pred_heartRate_test_m <- predict(fit_for_simp_heartRate_m, newdata = test_data_to_pred_heartRate_m)

# Predicting the classes to impute for BPMeds on the training and test data by first predicting numerical values in (0,1) and then classifying these to either 0 or 1. 
pred_BPMeds_train_m_probs <- predict(fit_for_simp_BPMeds_m, newdata = train_data_to_pred_BPMeds_m, type = "response") 
pred_BPMeds_test_m_probs <- predict(fit_for_simp_BPMeds_m, newdata = test_data_to_pred_BPMeds_m, type = "response")
pred_BPMeds_train_m <- ifelse(pred_BPMeds_train_m_probs >= 0.5, 1, 0)
pred_BPMeds_test_m <- ifelse(pred_BPMeds_test_m_probs >= 0.5, 1, 0)

# Predicting the classes to impute for education on the training and test data.
pred_edu_train_m <- predict(fit_for_simp_edu_m, newdata = train_data_to_pred_edu_m, type = "class") 
pred_edu_test_m <- predict(fit_for_simp_edu_m, newdata = test_data_to_pred_edu_m, type = "class")

```

To see how our predictions (on the training data) compare to the complete case, we plot (in different ways) the predicted values/classes.
For illustrating different types of plots, we plot glucose as a transparent histogram and as a point plot. 

```{r Missing data train-pred-plots}

# ---- Make transparent colors for plotting ----
c1 <- rgb(173,216,230,max = 255, alpha = 80, names = "lt.blue")
c2 <- rgb(255,192,203, max = 255, alpha = 80, names = "lt.pink")

# ---- Make histogram objects for glucose ----

# Histogram objects for glucose
hg_pred_gluc = hist(pred_glucose_train_m, plot = FALSE)
hg_old_gluc = hist(x.train_dat_m$glucose, plot = FALSE)


# ---- Make point plots over indexes for all except education ----

par(mfrow = c(2,3))

# Point plot for glucose
plot(x.train_dat_m$glucose, ylab = "Value of Glucose", main = "Glucose")
points(seq(1,length(x.train_dat_m[,1]),length.out = length(pred_glucose_train_m)),pred_glucose_train_m, col = "orange", pch = 16)
abline(h = mean(x.train_dat_m$glucose), col = "red")

# Point plot for cigsperday
plot(x.train_dat_m$cigs, ylab = "Value of cigsPerDay", main = "cigsPerDay")
points(seq(1,length(x.train_dat_m[,1]),length.out = length(pred_cigs_train_m)),pred_cigs_train_m, col = "orange", pch = 16)
abline(h = mean(x.train_dat_m$cigsPerDay), col = "red")

# Point plot for BMI
plot(x.train_dat_m$BMI, ylab = "Value of BMI", main = "BMI")
points(seq(1,length(x.train_dat_m[,1]),length.out = length(pred_BMI_train_m)),pred_BMI_train_m, col = "orange", pch = 16)
abline(h = mean(x.train_dat_m$BMI), col = "red")

# Point plot for totChol
plot(x.train_dat_m$totChol, ylab = "Value of totChol", main = "totChol")
points(seq(1,length(x.train_dat_m[,1]),length.out = length(pred_totChol_train_m)),pred_totChol_train_m, col = "orange", pch = 16)
abline(h = mean(x.train_dat_m$totChol), col = "red")

# Point plot for heartRate
plot(x.train_dat_m$heartRate, ylab = "Value of heartRate", main = "heartRate")
points(seq(1,length(x.train_dat_m[,1]),length.out = length(pred_heartRate_train_m)),pred_heartRate_train_m, col = "orange", pch = 16)
abline(h = mean(x.train_dat_m$heartRate), col = "red")

# Point plot for BPMeds
plot(x.train_dat_m$BPMeds, ylab = "Class of BPMeds", main = "BPMeds")
points(seq(1,length(x.train_dat_m[,1]),length.out = length(pred_BPMeds_train_m)),pred_BPMeds_train_m, col = "orange", pch = 16)
abline(h = mean(x.train_dat_m$BPMeds), col = "red")

# ---- Make histogram plots for glucose and education ----

par(mfrow = c(1,1))

# Histogram plots for glucose
plot(hg_old_gluc, col = c1, xlab = "Value of Glucose", main = "Glucose") # Plot 1st histogram using a transparent color
plot(hg_pred_gluc, , col = c2, add = TRUE)
legend("topright", legend=c("Observed - blue", "Predictions - pink"), cex=0.6)

par(mfrow = c(1,2))

# Histograms for education
plot(x.train_dat_m$education, main = "Education - Observed", ylab = "Frequency")
plot(pred_edu_train_m, main = "Education - Predicted", ylab = "Frequency")

```

Lastly, we update our data with the newly imputed values.

``` {r Missing Data imputation}

# ---- Making new data sets based on the old ones ----
x.train_imp = x.train_dat_m
x.test_imp = x.test_dat_m

# ---- We add the predictions to this data set. ----

# Adding glucose
x.train_imp[ici(x.train_imp$glucose),]$glucose <- pred_glucose_train_m
x.test_imp[ici(x.test_imp$glucose),]$glucose <- pred_glucose_test_m

# Adding cigsPerDay
x.train_imp[ici(x.train_imp$cigsPerDay),]$cigsPerDay <- pred_cigs_train_m
x.test_imp[ici(x.test_imp$cigsPerDay),]$cigsPerDay <- pred_cigs_test_m

# Adding BMI
x.train_imp[ici(x.train_imp$BMI),]$BMI <- pred_BMI_train_m
x.test_imp[ici(x.test_imp$BMI),]$BMI <- pred_BMI_test_m

# Adding totChol
x.train_imp[ici(x.train_imp$totChol),]$totChol <- pred_totChol_train_m
x.test_imp[ici(x.test_imp$totChol),]$totChol <- pred_totChol_test_m

# Adding heartRate
x.train_imp[ici(x.train_imp$heartRate),]$heartRate <- pred_heartRate_train_m
x.test_imp[ici(x.test_imp$heartRate),]$heartRate <- pred_heartRate_test_m

# Adding BPMeds
x.train_imp[ici(x.train_imp$BPMeds),]$BPMeds <- pred_BPMeds_train_m
x.test_imp[ici(x.test_imp$BPMeds),]$BPMeds <- pred_BPMeds_test_m

# Adding education
x.train_imp[ici(x.train_imp$education),]$education <- pred_edu_train_m
x.test_imp[ici(x.test_imp$education),]$education <- pred_edu_test_m

```

We should by now have obtained completely imputed data sets. 
To see this, we consider the missing data patterns of the newly constructed data sets.

``` {r Missing data final}

# For training data
md1 = md.pattern(x.train_imp)
gg_miss_var(x.train_imp)

# For test data
md2 = md.pattern(x.test_imp)
gg_miss_var(x.test_imp)

```

There are several steps in this procedure that could be improved. 

First of all, we could have used more flexible models for imputation than linear imputation, and we could have fit several different models on the training set and done evaluation procedures within the training set (e.g. cross validated optimization of ROC-AUC) to pick the models before fixing a model to impute each variable. 

Some variables, such as cigsPerDay, are in some sense discrete, although we have treated them as continuous (as it is possible to smoke e.g. $2,73$ cigaretts per day). These could have been rounded off to integers, but we didn't see why this would be necessary. 
We did not include the response (TenYearCHD) in the regressions. 
It is not clear to us why it would be a better choice to include it, as we don't want the imputed data to be overfitted towards the response.
We could might as well have included the response, if we wanted. 
More reading and testing would be needed to figure out the optimal solution, if there is any canonical choice.

The imputation was not done using the functions from the MICE package.
This is partially because we wanted to get our hands dirty and do it ourselves (for practice) and partially because we couldn't figure out how to use MICE to train a regression model on the training set and predict values on the test set using the same regression model.

# Model

In the model section we will consider two data sets: the complete case and imputed case. Both data sets are further divided into a train and test set. 

```{r complete train test}
# Split the complete data into training and test
r = dim(df_complete)[1]
size = round(r*tr)
train = sample(1:r,size = size)
X = model.matrix(TenYearCHD ~  ., data = df_complete)[,-1] # Remove the response
x.train_c = scale(X[train,])
x.test_c = scale(X[-train,])
y.train_c = df_complete$TenYearCHD[train]
y.test_c = df_complete$TenYearCHD[-train]


```


Given the binary response it is natural to consider fitting a logistic regression model to our data. Although we intend to use lasso, it is nice to start by fitting a regular logistic regression model to get an indication of which covariates that are most present, and for later comparison. 
```{r Logistic Model}
# Fit a logistic model
mod0 <- glm(TenYearCHD ~ ., data = df_complete[train,], family = binomial())
set.seed(294)
summary(mod0)
```

The logistic regression model chooses `r names(coefficients(mod0))[c(1,2,3,5,8,13,14,18)]` as the significant covariates. 

## Lasso on Complete Case 

Next we wish to do.
```{r Lasso}

# Use cross-validation to find lambda
cv.out = cv.glmnet(x.train_c, y.train_c, family = "binomial", intercept = F, alpha = 1)
plot(cv.out$glmnet.fit, "lambda", label=F)
plot(cv.out)
cv.out$lambda.min
cv.out$lambda.1se
lasso_mod = glmnet(x.train_c, y.train_c, family = "binomial", intercept = F, alpha = 1,  lasso = cv.out$lambda.1se)

lasso_coef <- coef(lasso_mod,s=cv.out$lambda.1se)
lasso_coef[,1]
``` 


```{r Bootstrap Lasso, eval = F}
B = 500

B_coef = matrix(NA, nrow = B, ncol = length(lasso_coef[,1]))
for (i in 1:B){
  data_b = sample(1:size, size = size, replace = TRUE)
  x = x.train_c[data_b,]
  y = y.train_c[data_b]
  cv.out = cv.glmnet(x, y, family = "binomial", alpha = 1)
  lasso_mod = glmnet(x, y, family = "binomial", alpha = 1, lasso = cv.out$lambda.1se)

  B_coef[i,] <- coef(lasso_mod,s=cv.out$lambda.1se)[,1]
}

colnames(B_coef) = names(coef(lasso_mod,s=cv.out$lambda.1se)[,1])
boxplot.matrix(B_coef[,-1], ylim = c(-0.25,0.55))

B_coef_count = ifelse(B_coef == 0,0,1)
apply(B_coef_count, 2, sum)
barplot(apply(B_coef_count, 2, sum)/B)
```

## Lasso on Imputed Data


# Inference

In order to do inference we simply fit a logistic regression model using the `glm` function in `R`, and extract the inference from there. However, we will keep the coefficients chosen by the lasso-bootstrapping iteration in last section, and now use the test data to fit a logistic model to avoid overfitting. 

```{r complete case comparison}
mod <- glm(TenYearCHD ~ 1 + age + male + sysBP, data = df_complete[-train,], family = binomial())

confint(mod)

confint(mod0)

```


# Discussion

STILL MISSING TO DO: 

Is lasso implemented correctly? 
Why is the bootstrap so slow? Final run should be with seed(8701) and B = 1000.
Copy paste the lasso code for imputed data.
Finish the inference and discussion. Mainly focus on comparison of complete case vs. imputed? 