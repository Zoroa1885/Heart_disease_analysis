---
subtitle: "MA8701 Advanced Statistical Learning V2023"
title: "Compulsory exercise: Team Supergreat"
author: "Nora Aasen, Elias Angelsen, Jonas Nordstr?m"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  html_document
  # pdf_document
---
  
```{r setup, include=FALSE}
library(knitr)
knitr::opts_chunk$set(echo = TRUE,tidy=TRUE,message=FALSE,warning=FALSE,strip.white=TRUE,prompt=FALSE,
                      cache=TRUE, size="scriptsize",
                      fig.width=4, fig.height=3,fig.align = "center")
```


# Setup

```{r Loading Packages,eval=TRUE,echo=FALSE}
# Load libraries
library(naniar)
library(mice)
library(glmnet)
library(dplyr)
library(caret)
library(ggcorrplot)
library(ggplot2)
library(e1071) #If we use KNN for imputation of education (multiclass)
```

Plan for the project: 
\begin{itemize}
\item Start by fitting lasso in bootstrap using complete data
\item Then singular imputation in training set and use same in test set
\item Fit a lasso within bootstrap
\item New method: still fitting lasso but this time do single imputation within the bootstrap
\item Compare the three different methods
\item Fit logistic regression and do inference under glm assumptions
\end{itemize}


New plan of 10.03?
Plan for the project: 
\begin{itemize}
\item Start by fitting lasso with bootstrap using complete data
\item Do single imputation (reg. with different models) in training set and use same in test set
\item Fit a lasso within bootstrap
\item Compare the two different methods
\item Fit logistic regression and do inference under glm assumptions
\end{itemize}



## Exploratory Analysis
```{r Loading Data}
# Load and look at data
# data <- framingham # Just if manual import
data <- read.csv("framingham.csv")
dim(data)
sum(data$TenYearCHD==1)
head(data)
str(data)

# Code education as a factor variable instead
data$education = factor(data$education, labels = c("none","hs","college","post-grad"))

# Look at the missing data
md.pattern(data)
gg_miss_var(data)

# Make a dataset containing only the complete cases
df_complete <- data[complete.cases(data), ]
dim(df_complete)
sum(df_complete$TenYearCHD==1)
str(df_complete)
# View(df_complete)
# Should we code the binary responses to be categorical instead of integers? 


# Split data into training and test
r = dim(df_complete)[1]
size = r-round(r/5)
spl = sample(1:r,size = size)
X = model.matrix(TenYearCHD ~  ., data = df_complete)[,-1]
x.train = X[spl,]
x.test = X[-spl,]
y.train = df_complete$TenYearCHD[spl]
y.test = df_complete$TenYearCHD[-spl]
```

```{r exp analysis}
# Make a correlation plot 
cor_mat = cor(df_complete)
ggcorrplot(cor_mat, hc.order = TRUE, type = "lower",
   outline.col = "white",
   colors = c("blue", "white", "red"))
```
## Missing Data

To treat the missing data, we will use single imputation, as multiple imputation may cause difficulties with the resulting inference, as Rubins rules need to be combined with the Lasso, bootstrap and concluding inference. 

The single imputation technique we will use is simply regression imputation, where we adapt our regression technique depending on the type of variable imputed. For continuous variables, we simply use a linear regression model. For binary variables, we use logistic regression to classify their values, and for the variable "education", which is a four-class variable, we have utilized kNN for multiclass imputation. 

To avoid encountering observations with more than one missing value, and hence problems with regressing, we remove all samples with more than one NA. 

Our data is split into training and test sets, of sizes approximately $80%$ and $20%$ of the original dataset, respectively.
In order to avoid data leakage in our imputation if the test set, we fit the imputation models on the training set.
Note that we do not include the response (TenYearCHD) in the regression, and in order to avoid too much correlation between the imputed samples, we always base the regression models on the complete case data, instead of letting the imputed values for variable $n$ regress to impute variable $n+1$.  

First, we are removing all samples with more than one covariate missing.

```{r Clean Missing Data}

# Setting seed expressing our love for MA8701
set.seed(8701)

# Throwing out the samples with two or more NAs from the data
miss <- c()
for(i in 1:nrow(data)) {
  if(sum(is.na(data[i,])) > 1){
    miss <- append(miss,i)
    }  
}

data_m <- data[-miss,]

# length(miss) # This number should be 61 if done correctly (61 came from manually counting in the md.pattern-plot below)

# Exploring data_m

md.pattern(data_m)
gg_miss_var(data_m)


```


We further split the data into a training and test set, following the training-test-ratio that we have previously set.

``` {r Missing data split}

# Assigning which values should go where by randomly sampling ~20% of the indices. 
dim_data_m = dim(data_m)[1]
size_split_m = dim_data_m-round(dim_data_m/5)
spl_dat_m = sample(1:dim_data_m, size = size_split_m)

# Making training and test data
train_data_m = data_m[spl_dat_m,]
test_data_m = data_m[-spl_dat_m,]

# Making training and test data for covariates and response separately.

X_dat_m = data_m[,-dim(data_m)[2]] # Remove the column with response?
x.train_dat_m = X_dat_m[spl_dat_m,]
x.test_dat_m = X_dat_m[-spl_dat_m,]
y.train_dat_m = data_m$TenYearCHD[spl_dat_m]
y.test_dat_m = data_m$TenYearCHD[-spl_dat_m]


```

Using the above data sets, we make regression models for each missing variable and predict the new values that are to be imputed.



``` {r Missing data predictions}

# We fit linear models on the training set for glucose, cigsPerDay,

fit_for_simp_glucose_m <- lm(glucose ~., data = x.train_dat_m) # Linear model for glucose
fit_for_simp_cigs_m <- lm(cigsPerDay ~., data = x.train_dat_m) # Linear model for cigsPerDay


```

```{r MD preds old}
#---------------------------------------------------------------------------------------------------------------
#------------------------------ Predicting and imputing new glucose data ---------------------------------------
#---------------------------------------------------------------------------------------------------------------


# Checking if this is good. It is not necessarily good, as R^2 is low, but since R^2 is positive, we are probably doing better than mean imputation. 
# summary(fit_for_simp_glucose_m)

## --- Prediction --- 

# Which should be predicted? # Pick out those variables with missing glucose values that we want to impute. 
train_data_to_pred_gluc_m = ic(x.train_dat_m)
train_data_to_pred_gluc_m = train_data_to_pred_gluc_m[ici(train_data_to_pred_gluc_m$glucose),] 

test_data_to_pred_gluc_m = ic(x.test_dat_m)
test_data_to_pred_gluc_m = test_data_to_pred_gluc_m[ici(test_data_to_pred_gluc_m$glucose),]


# Predict the variables with missing glucose values that we want to impute. 
pred_glucose_train_m <- predict(fit_for_simp_glucose_m, newdata = train_data_to_pred_gluc_m) 
pred_glucose_test_m <- predict(fit_for_simp_glucose_m, newdata = test_data_to_pred_gluc_m)


## --- Visuals ---

# Lets see what we predicted, using base plot. 

plot(x.train_dat_m$glucose)
points(seq(1,length(x.train_dat_m[,1]),length.out = length(pred_glucose_train_m)),pred_glucose_train_m, col = "orange")
abline(h = mean(x.train_dat_m$glucose), col = "red")

# Can also do this by making histogram objects

hg_pred_gluc = hist(pred_glucose_train_m, plot = FALSE)
hg_old_gluc = hist(x.train_dat_m$glucose, plot = FALSE)

# Make transparent colors
c1 <- rgb(173,216,230,max = 255, alpha = 80, names = "lt.blue")
c2 <- rgb(255,192,203, max = 255, alpha = 80, names = "lt.pink")

# Plot together
plot(hg_old_gluc, col = c1) # Plot 1st histogram using a transparent color
plot(hg_pred_gluc, , col = c2, add = TRUE)


## Add predictions into original data by changing those with incomplete glucose


x.train_dat_m[ici(x.train_dat_m$glucose),]$glucose <- pred_glucose_train_m
x.test_dat_m[ici(x.test_dat_m$glucose),]$glucose <- pred_glucose_test_m

# Run these to see that we eliminated the missing variables.

md.pattern(x.train_dat_m)
gg_miss_var(x.train_dat_m)

md.pattern(x.test_dat_m)
gg_miss_var(x.test_dat_m)


# We continue to do this with the other cont. variables {Cigs per day, BMI, TotChol, HR (only for training data)}, based on the original complete case.

#---------------------------------------------------------------------------------------------------------------
#-------------------------- Predicting and imputing new data for Cigs Per Day ----------------------------------
#---------------------------------------------------------------------------------------------------------------


# Checking if this is good. It is not necessarily good, as R^2 is low, but since R^2 is positive, we are probably doing better than mean imputation. 
# summary(fit_for_simp_cigs_m)

## --- Prediction --- 

# Which should be predicted? # Pick out those variables with missing glucose values that we want to impute. 
train_data_to_pred_cigs_m = ic(x.train_dat_m)
train_data_to_pred_cigs_m = train_data_to_pred_cigs_m[ici(train_data_to_pred_cigs_m$cigsPerDay),]

test_data_to_pred_cigs_m = ic(x.test_dat_m)
test_data_to_pred_cigs_m = test_data_to_pred_cigs_m[ici(test_data_to_pred_cigs_m$cigsPerDay),]


# Predict the variables with missing glucose values that we want to impute.
pred_cigs_train_m <- predict(fit_for_simp_cigs_m, newdata = train_data_to_pred_cigs_m) 
pred_cigs_test_m <- predict(fit_for_simp_cigs_m, newdata = test_data_to_pred_cigs_m)


## --- Visuals ---

## Lets see what we predicted

plot(x.train_dat_m$cigs)
plot(pred_cigs_train_m)

# Make histogram objects

hg_pred_cigs = hist(pred_cigs_train_m, plot = FALSE)
hg_old_cigs = hist(x.train_dat_m$cigsPerDay, plot = FALSE)

# Plot together (basically useless because of few samples, but can probably fix that).
plot(hg_old_cigs, col = c1) # Plot 1st histogram using a transparent color
plot(hg_pred_cigs, , col = c2, add = TRUE)


## Add predictions into original data by changing those with incomplete cigsPerDay


x.train_dat_m[ici(x.train_dat_m$cigsPerDay),]$cigsPerDay <- pred_cigs_train_m
x.test_dat_m[ici(x.test_dat_m$cigsPerDay),]$cigsPerDay <- pred_cigs_test_m

md.pattern(x.train_dat_m)
gg_miss_var(x.train_dat_m)

md.pattern(x.test_dat_m)
gg_miss_var(x.test_dat_m)

# We continue to do this with the other continuous variables {BMI, TotChol, HR (only for training data)}


#---------------------------------------------------------------------------------------------------------------
#-------------------------- Predicting and imputing new data for BMI -------------------------------------------
#---------------------------------------------------------------------------------------------------------------



# We fit a linear model on the training set.

fit_for_simp_BMI_m <- lm(BMI ~., data = x.train_dat_m) # Q: Should the response be included? Open question :( We think no. Argue why later!

# Checking if this is good. It is not necessarily good, as R^2 is low, but since R^2 is positive, we are probably doing better than mean imputation.
# summary(fit_for_simp_BMI_m)

## --- Prediction --- 

# Which should be predicted?
train_data_to_pred_BMI_m = ic(x.train_dat_m)
train_data_to_pred_BMI_m = train_data_to_pred_BMI_m[ici(train_data_to_pred_BMI_m$BMI),]

test_data_to_pred_BMI_m = ic(x.test_dat_m)
test_data_to_pred_BMI_m = test_data_to_pred_BMI_m[ici(test_data_to_pred_BMI_m$BMI),]


# Predict them
pred_BMI_train_m <- predict(fit_for_simp_BMI_m, newdata = train_data_to_pred_BMI_m) 
pred_BMI_test_m <- predict(fit_for_simp_BMI_m, newdata = test_data_to_pred_BMI_m)



## --- Visuals ---

## Lets see what we predicted

plot(x.train_dat_m$BMI)
plot(pred_BMI_train_m)

# Make histogram objects

hg_pred_BMI = hist(pred_BMI_train_m, plot = FALSE)
hg_old_BMI = hist(x.train_dat_m$BMI, plot = FALSE)

# Plot together (basically useless because of few samples, but can probably fix that).
plot(hg_old_BMI, col = c1) # Plot 1st histogram using a transparent color
plot(hg_pred_BMI, col = c2, add = TRUE)


## Add predictions into original data by changing those with incomplete BMI


x.train_dat_m[ici(x.train_dat_m$BMI),]$BMI <- pred_BMI_train_m
x.test_dat_m[ici(x.test_dat_m$BMI),]$BMI <- pred_BMI_test_m

md.pattern(x.train_dat_m)
gg_miss_var(x.train_dat_m)

md.pattern(x.test_dat_m)
gg_miss_var(x.test_dat_m)

# We continue to do this with the other continuous variables {TotChol, HR (only for training data)}


#---------------------------------------------------------------------------------------------------------------
#-------------------------- Predicting and imputing new data for TotChol ---------------------------------------
#---------------------------------------------------------------------------------------------------------------



# We fit a linear model on the training set.

fit_for_simp_totChol_m <- lm(totChol ~., data = x.train_dat_m) # Q: Should the response be included? Open question :( We think no. Argue why later!

# Checking if this is good. It is not necessarily good, as R^2 is low, but since R^2 is positive, we are probably doing better than mean imputation.
# summary(fit_for_simp_totChol_m)

## --- Prediction --- 

# Which should be predicted?
train_data_to_pred_totChol_m = ic(x.train_dat_m)
train_data_to_pred_totChol_m = train_data_to_pred_totChol_m[ici(train_data_to_pred_totChol_m$totChol),]

test_data_to_pred_totChol_m = ic(x.test_dat_m)
test_data_to_pred_totChol_m = test_data_to_pred_totChol_m[ici(test_data_to_pred_totChol_m$totChol),]


# Predict them
pred_totChol_train_m <- predict(fit_for_simp_totChol_m, newdata = train_data_to_pred_totChol_m) 
pred_totChol_test_m <- predict(fit_for_simp_totChol_m, newdata = test_data_to_pred_totChol_m)


## --- Visuals ---

## Lets see what we predicted

plot(x.train_dat_m$totChol)
plot(pred_totChol_train_m)

# Make histogram objects

hg_pred_totChol = hist(pred_totChol_train_m, plot = FALSE)
hg_old_totChol = hist(x.train_dat_m$totChol, plot = FALSE)

# Plot together (basically useless because of few samples, but can probably fix that).
plot(hg_old_totChol, col = c1) # Plot 1st histogram using a transparent color
plot(hg_pred_totChol, col = c2, add = TRUE)


## Add predictions into original data by changing those with incomplete TotChol


x.train_dat_m[ici(x.train_dat_m$totChol),]$totChol <- pred_totChol_train_m
x.test_dat_m[ici(x.test_dat_m$totChol),]$totChol <- pred_totChol_test_m

md.pattern(x.train_dat_m)
gg_miss_var(x.train_dat_m)

md.pattern(x.test_dat_m)
gg_miss_var(x.test_dat_m)

# We continue to do this with the other continuous variables {HR (only for training data)}

#---------------------------------------------------------------------------------------------------------------
#-------------------------- Predicting and imputing new data for HR (training data) ----------------------------
#---------------------------------------------------------------------------------------------------------------



# We fit a linear model on the training set.

fit_for_simp_heartRate_m <- lm(heartRate ~., data = x.train_dat_m) 

# Checking if this is good. It is not necessarily good, as R^2 is low, but since R^2 is positive, we are probably doing better than mean imputation.
# summary(fit_for_simp_heartRate_m)

## --- Prediction --- 

# Which should be predicted?
train_data_to_pred_heartRate_m = ic(x.train_dat_m)
train_data_to_pred_heartRate_m = train_data_to_pred_heartRate_m[ici(train_data_to_pred_heartRate_m$heartRate),]


# Predict
pred_heartRate_train_m <- predict(fit_for_simp_heartRate_m, newdata = train_data_to_pred_heartRate_m) 

## Add predictions into original data by changing those with incomplete HR


x.train_dat_m[ici(x.train_dat_m$heartRate),]$heartRate <- pred_heartRate_train_m

md.pattern(x.train_dat_m)
gg_miss_var(x.train_dat_m)

md.pattern(x.test_dat_m)
gg_miss_var(x.test_dat_m)

# We continue to do this with the binary variable BP, using logistic regression for classification.



#---------------------------------------------------------------------------------------------------------------
#-------------------------- Predicting and imputing new data for BPMeds (Binary) -------------------------------
#---------------------------------------------------------------------------------------------------------------



# We fit a logistic model on the training set.

fit_for_simp_BPMeds_m <- glm(BPMeds ~., data = x.train_dat_m, family = "binomial")

# Checking if this is good. It is not necessarily good, as R^2 is low, but since R^2 is positive, we are probably doing better than mean imputation.
# summary(fit_for_simp_BPMeds_m)

## --- Prediction --- 

# Which should be predicted?
train_data_to_pred_BPMeds_m = ic(x.train_dat_m)
train_data_to_pred_BPMeds_m = train_data_to_pred_BPMeds_m[ici(train_data_to_pred_BPMeds_m$BPMeds),]

test_data_to_pred_BPMeds_m = ic(x.test_dat_m)
test_data_to_pred_BPMeds_m = test_data_to_pred_BPMeds_m[ici(test_data_to_pred_BPMeds_m$BPMeds),]


# Predict them (first numerically in (0,1), then classify to 0 or 1 depending on value)
pred_BPMeds_train_m_probs <- predict(fit_for_simp_BPMeds_m, newdata = train_data_to_pred_BPMeds_m, type = "response") 
pred_BPMeds_test_m_probs <- predict(fit_for_simp_BPMeds_m, newdata = test_data_to_pred_BPMeds_m, type = "response")

pred_BPMeds_train_m <- ifelse(pred_BPMeds_train_m_probs >= 0.5, 1, 0)
pred_BPMeds_test_m <- ifelse(pred_BPMeds_test_m_probs >= 0.5, 1, 0)


## --- Visuals ---

## Lets see what we predicted

plot(x.train_dat_m$BPMeds)
plot(pred_BPMeds_train_m) # Seems like a reasonable (~ 1/41) was classified as 1, compared to the training data. 

# Make histogram objects

hg_pred_BPMeds = hist(pred_BPMeds_train_m, plot = FALSE)
hg_old_BPMeds = hist(x.train_dat_m$BPMeds, plot = FALSE)

# Plot together (basically useless because of few samples, but can probably fix that).
plot(hg_old_BPMeds, col = c1) # Plot 1st histogram using a transparent color
plot(hg_pred_BPMeds, col = c2, add = TRUE)


## Add predictions into original data by changing those with incomplete BPMeds


x.train_dat_m[ici(x.train_dat_m$BPMeds),]$BPMeds <- pred_BPMeds_train_m
x.test_dat_m[ici(x.test_dat_m$BPMeds),]$BPMeds <- pred_BPMeds_test_m

md.pattern(x.train_dat_m)
gg_miss_var(x.train_dat_m)

md.pattern(x.test_dat_m)
gg_miss_var(x.test_dat_m)

# We continue to do this with the last variable, education, which is a four-class variable. We use KNN.



#---------------------------------------------------------------------------------------------------------------
#-------------------------- Predicting and imputing new data for Education (Multiclass) ------------------------
#---------------------------------------------------------------------------------------------------------------


# We fit a KNN model for classification on the training set.

fit_for_simp_edu_m <- gknn(education ~., data = x.train_dat_m)

## --- Prediction --- 

# Which should be predicted?
train_data_to_pred_edu_m = ic(x.train_dat_m)
train_data_to_pred_edu_m = train_data_to_pred_edu_m[ici(train_data_to_pred_edu_m$education),]

test_data_to_pred_edu_m = ic(x.test_dat_m)
test_data_to_pred_edu_m = test_data_to_pred_edu_m[ici(test_data_to_pred_edu_m$education),]


# Predict them
pred_edu_train_m <- predict(fit_for_simp_edu_m, newdata = train_data_to_pred_edu_m, type = "class") 
pred_edu_test_m <- predict(fit_for_simp_edu_m, newdata = test_data_to_pred_edu_m, type = "class")

## --- Visuals ---

## Lets see what we predicted

plot(x.train_dat_m$education)
plot(pred_edu_train_m) # Seems like a reasonable (~ 1/41) was classified as 1, compared to the training data. 

## Add predictions into original data by changing those with incomplete education.


x.train_dat_m[ici(x.train_dat_m$education),]$education <- pred_edu_train_m
x.test_dat_m[ici(x.test_dat_m$education),]$education <- pred_edu_test_m

md.pattern(x.train_dat_m)
gg_miss_var(x.train_dat_m)

md.pattern(x.test_dat_m)
gg_miss_var(x.test_dat_m)



```

There are several steps in this procedure that could be improved upon. First of all, we could have used more flexible models for imputation than linear imputation, and we could have fit several models on the training set and done an evaluation procedure within the training set (e.g. cross validated optimization of ROC-AUC) to pick the models imputing each variable. 

As mentioned, we did not include the response (TenYearCHD) in the regressions. It is not clear to us why it would be a better choice to include it. More reading and testing would be needed to figure out the optimal solution, if there is any canonical choice.



# Model

## Naive Approach
```{r Logistic Model}
# Fit a logistic model
mod0 <- glm(TenYearCHD ~ ., data = df_complete, family = binomial())

summary(mod0)
```


## Lasso
```{r Lasso}
# Må vi fjerne intercept før lasso? 

# Use cross-validation to find lambda
cv.out = cv.glmnet(x.train, y.train, family = "binomial", alpha = 1)
plot(cv.out$glmnet.fit, "lambda", label=FALSE)
plot(cv.out)
cv.out$lambda.min
cv.out$lambda.1se
lasso_mod = glmnet(x.train, y.train, family = "binomial", alpha = 1, lasso = cv.out$lambda.1se)

lasso_coef <- coef(lasso_mod,s=cv.out$lambda.1se)
lasso_coef[,1]
``` 




```{r Bootstrap Lasso}
B = 1000

B_coef = matrix(NA, nrow = B, ncol = 16)
for (i in 1:B){
  print(i)
  spl_b = sample(1:size, size = size, replace = TRUE)
  x = x.train[spl_b,]
  y = y.train[spl_b]
  cv.out = cv.glmnet(x, y, family = "binomial", alpha = 1)
  lasso_mod = glmnet(x.train, y.train, family = "binomial", alpha = 1, lasso = cv.out$lambda.1se)

  B_coef[i,] <- coef(lasso_mod,s=cv.out$lambda.1se)[,1]
}

colnames(B_coef) = names(coef(lasso_mod,s=cv.out$lambda.1se)[,1])
B_coef = ifelse(B_coef == 0,0,1)
apply(B_coef, 2, sum)

```

## Ridge 
```{r Ridge Model}
response <- "TenYearCHD"
features <- names(df_complete)[!names(df_complete) %in% c("TenYearCHD")]

df_complete["education"] <- factor(df_complete$education, labels = c("None", "HighSchool", "Collage", "Grad"))

X <- model.matrix(~.-1, df_complete[features])
y <- df_complete[response]

train_frac = 0.8
train.ind <- sample(c(TRUE, FALSE), nrow(df_complete),
                    replace=TRUE, prob=c(train_frac, 1-train_frac))

X_train <- X[train.ind,]
X_test <- X[!train.ind,]

y_train <- y[train.ind,]
y_test <- y[!train.ind,]

ridge_cv <- cv.glmnet(X_train, y_train, family = "binomial", alpha = 0)

plot(ridge_cv)
lambda_min = ridge_cv$lambda.min
lambda_1se = ridge_cv$lambda.1se
cat("Lambda min:", lambda_min, "\n")
cat("Lambda 1se:", lambda_1se)


print(ridge_cv)
coef(ridge_cv, s = "lambda.1se")
```
Make a fit with the best lambda and measuring error
```{r}
ridge_fit = glmnet(X_train, y_train, lambda = lambda_min, alpha = 0, family = "binomial")
ridge_pred = predict(ridge_fit, X_test, type = "class")

ridge_pred_class = factor(round(ridge_pred))
y_test <- factor(y_test)

conf_mat <- confusionMatrix(ridge_pred_class, y_test)
conf_mat

mse_ridge = mean((ridge_pred - y_test)^2)
mse_ridge
```

